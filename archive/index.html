<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0"/>
    <title>Big</title>
    <style>
      .responsive-iframe {
        position: absolute;
        top: 0;
        left: 0;
        bottom: 0;
        right: 0;
        width: 100%;
        height: 100%;
        border: none;
      }

      .photo-credit {
        position: absolute;
        bottom: 10px;
        right: 10px;
        font-size: 16px;
      }
    </style>
    <link href="styles/components/big.css" rel="stylesheet" type="text/css"/>
    <link href="styles/themes/brutalist-2.css" rel="stylesheet" type="text/css"/>
    <script src="js/index-citations-global.js"></script>

    <script src="big.js"></script>
    <script src="js/lazysizes.min.js"></script>
    <script src="js/broadcast.js"></script>
  </head>

  <body class="light">

    <!-- Title slide  -->
    <div class="layout"
    style="grid-template-rows: repeat(5, minmax(0, 1fr)); grid-template-columns: repeat(6, 1fr); gap: 10px; height: 100vh;">
      <!-- Main title -->
      <div style="grid-row: 1 / 2; grid-column: 1 / 7;">
      RESEARCH <br> AND CREATIVE WORK
    </div>

      <!-- Subtitle -->
      <!-- <div style="grid-row: 1 / 2; grid-column: 5 / 7;">2024</div> -->

      <!-- Description text -->
      <div style="grid-row: 3; grid-column: 2 / 6;">
        <span class="underline">From Participatory Mobile Music to
        Locative Sound Art</span>
      </div>

      <!-- Author/presenter info -->
      <div style="grid-row: 5; grid-column: 1 / 4;">Tate Carson, PhD</div>
      <div style="grid-row: 5; grid-column: 4 / 7;">Assistant Professor of Digital Sound Design</div>
      <notes>
      Introduction; mobile music and locative sound art with smartphones.

    </notes>
      <div class="slide-count"></div>

    </div>

    <div
    style="display: grid; grid-template-rows: repeat(6, 1fr); grid-template-columns: repeat(6, 1fr); gap: 5px; height:100vh ">
      <!-- Main title that establishes the topic -->
      <div style="grid-row: 1 / 3; grid-column: 1 / 7;">THE SMARTPHONE AS ARTISTIC PLATFORM</div>

      <!-- Core aspects in a structured layout -->
      <div style="grid-row: 3 / 4; grid-column: 2 / 4;">
        <span class="border">UBIQUITY</span>
      </div>
      <div class="underline" style="grid-row: 3 / 4; grid-column: 6 / 7;">Open access</div>

      <div style="grid-row: 4 / 5; grid-column: 1 / 3;">
        <span class="border">SENSORS</span>
      </div>
      <div class="underline" style="grid-row: 4 / 5; grid-column: 4 / 8;">GPS, gyroscope, microphone integration</div>

      <div style="grid-row: 6 / 7; grid-column: 2 / 4;">
        <span class="border">NETWORKS</span>
      </div>
      <div class="underline" style="grid-row: 6/7; grid-column: 5 / 8;">Distributed and collaborative music-making</div>

      <!-- Bottom row emphasizing the broader impact -->
      <!-- <div style="grid-row: 6 / 7; grid-column: 1 / 7;">Transforming our relationship with sound, environment, and
      technology</div> -->

      <notes>
      * A few things that make smartphones particularly interesting for music and sound art are their ubiquity, many
      people already have one in their pocket, the sensors that come with them, like GPS, gyroscope, and microphone, and
      the networks that they can connect to, allowing for the creation of collaborative digital musical experiences.
      * These features allow for new ways of creating and experiencing music, and can transform our relationship with
      sound, environment, and technology.
    </notes>
      <div class="slide-count"></div>

    </div>

    <div class="layout" style="grid-template-rows: repeat(6, 1fr); grid-template-columns: repeat(8, 1fr); gap: 10px;">
      <div style="grid-row: 1 / 2; grid-column: 1 / 5;">
        <span class="underline">And the water receded</span>
      </div>
      <div style="grid-row: 1 / 2; grid-column: 6;">
        <span class="border">2017</span>
      </div>

      <!-- Second work aligned with the first for temporal connection -->
      <div style="grid-row: 2 / 3; grid-column: 4/7;">
        <span class="underline">A more perfect union</span>
      </div>
      <div style="grid-row: 2 / 3; grid-column: 8;">
        <span class="border">2017</span>
      </div>

      <div style="grid-row: 3; grid-column: 2 / 4;">
        <span class="underline">Mesh Garden</span>
      </div>
      <div style="grid-row: 3; grid-column: 6;">
        <span class="border">2018</span>
      </div>

      <!-- Middle period work spans wider, suggesting its duration -->
      <div style="grid-row: 4; grid-column: 1 / 4;">
        <span class="underline">Sounds Aware</span>
      </div>
      <div style="grid-row: 4; grid-column: 4 / 7;">
        <span class="border">2019-2021</span>
      </div>

      <!-- Recent works create dynamic tension through positioning -->
      <div style="grid-row: 5; grid-column: 3 / 6;">
        <span class="underline">immaterial.cloud</span>
      </div>
      <div style="grid-row: 5; grid-column: 8;">
        <span class="border">2020</span>
      </div>

      <!-- Latest work emphasized through full width -->
      <div style="grid-row: 6; grid-column: 2 / 5;">
        <span class="underline">Resonant Landscapes</span>
      </div>
      <div style="grid-row: 6; grid-column: 6 / 8;">
        <span class="border">2023-Present</span>
      </div>

      <notes>
      * I'll give an overview of the progression of my work over the past few years, starting with And the water receded
      in 2017, then moving on to A more perfect union, Mesh Garden, Sounds Aware, immaterial.cloud, and finally my most
      recent work Resonant
      Landscapes.
      * These works have explored different aspects of mobile music and locative sound art, and have built on
      each other to create a body of work that explores the potential of the smartphone as an artistic platform.
    </notes>
      <div class="slide-count"></div>

    </div>

    <div class="layout"
    style="grid-template-rows: repeat(6, minmax(0, 1fr)); grid-template-columns: repeat(6, 1fr); gap: 0px;">
      <!-- Primary title section takes full width at top with strong presence -->
      <div style="grid-row: 1 / 2; grid-column: 1 / 5;">
        <span class="underline">
        And the water receded
      </span>

      </div>
      <div style="grid-row: 1 / 2; grid-column: 7;">
        <span class="year">
        2017

      </span>
      </div>

      <!-- Core concept gets prominent secondary position -->
      <div style="grid-row: 2 / 3; grid-column: 2 / 6;">Sonification of Hurricane Katrina</div>

      <div style="grid-row: 3/6; grid-column:5/7">
        <img src="images/and-the-water.jpg" alt="">
      </div>

      <!-- Tools list indented and stacked -->
      <div style="grid-row: 4 / 6; grid-column: 2 / 5;">
      Networked Animated Notation
    </div>

      <div style="grid-row: 6 / 7; grid-column: 4 / 8;">Stepping Stone to Participatory Works &#8594;</div>
      <notes>

      ## Background

      * *And the water receded* is a musical piece that sonifies Hurricane Katrina data for three performers and
      electronics, condensing the storm's timeline from formation to landfall. Sonification is a process that takes data
      and translates it into sound.
      * The work stems from my personal hurricane experiences and uses animated smartphone-based notation to synchronize
      performers with
      electronics. Animated notation refers to any form of musical or sonic score in which the visual elements change or
      move over time,
      often in synchronization with performance or as a cue for interpretation.
      * “Musical Sonification of Hurricane Katrina and Its Aftermath.” Master, Mills College, 2017.

      ## Data
      * The first movement, *And the waters returned*, transforms storm data (latitude, longitude, wind
      speed, and air pressure) into musical parameters, using saw waves and noise to reflect the storm's chaotic nature.
      The second movement, *What remained*, derives melodies from recovered family recipes.

      ## Development
      * Initially using smartphones only for score
      display, later adaptations employed them as distributed speakers when traditional multichannel systems weren't
      available, establishing groundwork for future smartphone-based musical works.
    </notes>
      <div class="slide-count"></div>

    </div>

    <div>

      <iframe class="responsive-iframe lazyload"
      src="https://www.youtube.com/embed/es_4M9t9K-4?si=N1-zD5QbFOD85nhW&amp;start=330" title="YouTube video player"
      frameborder="0"
      allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
      referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
      <div class="slide-count"></div>
      <notes>A performance at Mills College in 2017</notes>
    </div>

    <div class="layout"
    style="grid-template-rows: repeat(4, minmax(0, 1fr)); grid-template-columns: repeat(6, 1fr); gap: 10px;">
      <!-- Large hero image takes up most of the left side -->
      <div style="grid-row: 1 / 4; grid-column: 1 / 4;">
        <img src="images/ampu.png"/>
      </div>

      <!-- Title and descriptive text on the right -->
      <div style="grid-row: 1 / 2; grid-column: 4 / 7;">
        <span class="underline">A more perfect union</span>
      </div>

      <!-- Exhibition details -->
      <div style="grid-row: 3 / 4; grid-column: 4 / 7;">
      Direct Audience Control
    </div>

      <!-- Footer information spans full width -->
      <div style="grid-row: 4 / 5; grid-column: 1 / 3;">
        <span class="year">2017</span>
      </div>
      <div style="grid-row: 4 / 5; grid-column: 3 / 7;">
      Smartphone Speaker Array
    </div>

      <notes>
      * A More Perfect Union was conceived as a direct response to the limitations of And the Water Receded, exploring
      innovative approaches to creating and experiencing music on smartphones.
      * Utilizing a smartphone speaker array, the
      work provided an immersive and interactive experience for the audience.
      * Guided by audience evaluations, melodies evolved through a genetic algorithm,
      resulting in an emergent sound that reflected collective preferences.
      * I saw this work as a precursor to more fully participatory compositions.
      * Carson, Tate. “A More Perfect Union: Composition with Audience-Controlled Smartphone Speaker Array and
      Evolutionary Computer Music.” In Proceedings of the Web Audio Conference. Berlin, Germany, 2018.
    </notes>
      <div class="slide-count"></div>

    </div>

    <div>
      <iframe title="vimeo-player" class="responsive-iframe lazyload" src="https://player.vimeo.com/video/267062963"
      frameborder="0" allowfullscreen></iframe>
      <notes>This is a performance version of the work that took place at LSU Museum
      of Art on March 4, 2018</notes>
      <div class="slide-count"></div>

    </div>

    <div>
      <div>Breaking the Audience / Performer Divide</div>
      <notes>
      * The audience transitions from passive listeners to active creators in *A more perfect union*, with all
      participants serving dual roles as both audience and performers, eliminating traditional performer-audience
      boundaries
      * Participation requires no musical expertise - audience members simply express preferences by choosing to listen
      to or skip melodies, making the work accessible while allowing them to drive its evolution
      * The work functions as a conceptual experiment focused on collective creation rather than predetermined musical
      outcomes
    </notes>
      <div class="slide-count"></div>

    </div>
    <div class="layout" style="grid-template-rows: 75% 25%">
      <img src="./images/amoreperfectunion/League_FtM_perf.jpg" alt=""/>

      <div>
      The League of Automatic Music Composers (Perkis, Horton, and Bischoff,
      left to right) performing at Ft. Mason, San Francisco 1981.
      <br/>

      </div>
      <em class="photo-credit">photo: Peter Abramowitsch</em>

      <notes>
      * A precursor to this concept of distributed control of a composition can
      be found in the early computer networked music groups The League of
      Automatic Music Composers and later The Hub.
      * They created networks of
      computers that would send messages to other computers to create a rich
      texture of evolving sounds.
    </notes>
      <div class="slide-count"></div>

    </div>
    <div>
      <img src="./images/amoreperfectunion/sims-galapagos.jpg" alt="an image of Karl Sims' Galapagos installation"/>

      <div>Karl Sims' Galapagos (1997)</div>

      <em class="photo-credit">photo: Ohtaka Takashi</em>
      <notes>
      * Another important conceptual precursor to the work is Karl Sims' 1997
      installation Galapagos. Sims' work consisted of several video screens,
      each displaying a different virtual organism.
      * The installation allowed
      spectators to take part in evolving virtual organisms by choosing the
      amount of time they spent in front of one video screen versus another.
      * The longer a viewer stood in front of a screen, the more he increased
      the fitness of that virtual organism, and made it more likely for the
      organism to pass its traits onto the next generation.
    </notes>
      <div class="slide-count"></div>

    </div>

    <div class="layout"
    style="display: grid; grid-template-rows: repeat(4, 1fr); grid-template-columns: repeat(6, 1fr); gap: 10px;">
      <!-- Central image -->
      <div style="grid-row: 2 / 4; grid-column: 2 / 5;">
        <img src="images/mesh-garden-2.png" style="width: 100%; height: 100%;" alt="Featured image"/>
      </div>

      <!-- Surrounding text -->
      <div style="grid-row: 1 / 2; grid-column: 1 / 7;">
        <span class="underline">Mesh Garden</span>
      </div>
      <div style="grid-row: 2 / 4; grid-column: 1 / 2;">
        <span class="year">2018</span>
      </div>
      <div style="grid-row: 2 / 4; grid-column: 5 / 7;">Musical Game</div>
      <div style="grid-row: 4 / 5; grid-column: 1 / 3;">Gyroscope</div>
      <div style="grid-row: 4 / 5; grid-column: 5 / 7;">Party Music</div>

      <notes>
      * *Mesh Garden* is a participatory music game, using smartphones as speakers/controllers in social settings, where
      players interact with each other to create ambient music via a web interface
      * The system enables creative musical interaction through phone orientation and compass heading matching - when
      phones face each other, players can trade notes, fostering non-competitive creative orchestration
      * “Mesh Garden: A Creative-Based Musical Game for Participatory Musical Performance.” In Proceedings of the
      International Conference on New Interfaces for Musical Expression, 339–42. Porto Alegre, Brazil, 2019.
    </notes>
      <div class="slide-count"></div>

    </div>

    <div>
      <iframe class="responsive-iframe azyload" src="https://www.youtube.com/embed/_WQHdGdvO2E" frameborder="0"
      allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
      allowfullscreen></iframe>

      <notes>
      Here's a video of the piece in action. The video shows a group of people playing the game, interacting with each
      other.

    </notes>
      <div class="slide-count"></div>

    </div>

    <div class="layout" style="grid-template-rows: 75% 25%">
      <img src="images/mesh-garden/Guitar-GH3-hammeron.0.webp" alt=""/>
      <div>Guitar Hero</div>
      <div class="credit">
        <em class="photo-credit"> Photo: <a href="https://polygon.com">polygon.com</a>
        </em>

      </div>
      <notes>
      * *Mesh Garden* contrasts with mimicry games like *Guitar Hero* which recreate existing songs
      * Core gameplay involves musical decision-making through phone orientation and player interaction, with mechanics
      designed for creating new music rather than reproducing predetermined scores
      * Following Thomas Studley's framework, *Mesh Garden* meets creative-based game criteria: gameplay centers on
      musical decisions, players directly influence music production, and actions are framed as creating new music
    </notes>
      <div class="slide-count"></div>

    </div>

    <!--
  <div class="layout" style="grid-template-rows: 75% 25%">
    <img src="images/mesh-garden/instantcity_play.jpg" alt="" />
    <div style="font-size: 1.5em">Instant City (2003-2006)</div>
    <div>
      <div class="credit">
        <em class="photo-credit">Photo: <a
            href="http://www.hauert-reichmuth.ch/en/projekte/instant-city/">http://www.hauert-reichmuth.ch/en/projekte/instant-city/</a></em>

      </div>
    </div>
    <notes>
      * *Instant City* is a music-building game using blocks on a light table that translates block configurations into
      music, featuring ambient gameplay focused on exploration without predetermined goals
      * *Mesh Garden* drew inspiration from *Instant City's* ambient gameplay style and interactive music creation,
      while improving accessibility through web-based mobile technology
    </notes>
    <div class="slide-count"></div>

  </div>

 -->

    <!-- Sounds Aware -->
    <div class="layout"
    style="grid-template-rows: repeat(4, minmax(0, 1fr)); grid-template-columns: repeat(6, 1fr); gap: 10px;">
      <!-- Large hero image takes up most of the left side -->

      <!-- Title and descriptive text on the right -->
      <div style="grid-row: 1 / 2; grid-column: 1 / 4;">
        <span class="underline">Sounds Aware</span>
      </div>

      <!-- Exhibition details -->
      <div style="grid-row: 3 / 4; grid-column: 1/4;">
      Locative Audio Sound Art
    </div>

      <div style="grid-row: 1 / 4; grid-column: 4/ 7;">
        <img src="images/sounds-aware.png"/>
      </div>

      <!-- Footer information spans full width -->
      <div style="grid-row: 4 / 5; grid-column: 1 / 3;">
        <span class="year">2019 — 2021</span>
      </div>
      <div style="grid-row: 4 / 5; grid-column: 3 / 7;">
      An app for sharing sound walks
    </div>

      <notes>
      * After Mesh Garden, I became interested in leveraging the mobility of smartphones to create experiences designed
      for outdoor environments and walking.
      * This led to Sounds Aware, a locative audio sound art project that fostered a
      shared experience of the environment through sound. Developed as a web app, the project enabled users to share
      sound walks, creating a collective soundscape that reflected the diversity of their surroundings.
      * Running from
      2019 to 2021, Sounds Aware explored the potential of locative audio as a medium for crafting shared environmental
      experiences.
      * “Using Distributed Technology to Make Music in the Time of the Attention Economy.” Phd, Louisiana State
      University and Agricultural & Mechanical College, 2021.
    </notes>
      <div class="slide-count"></div>

    </div>

    <div class="fancy-quote">
      <blockquote>

      To what extent might the technologies of communication, art and
      entertainment serve as 'prostheses' that would provide us with
      experiences of wilderness that would not only enrich our human
      identity but help us to preserve and expand the domain of the
      non-human world?

    </blockquote>
      <!-- <div style="text-align: right;">- David Dunn</div> -->

      <em class="photo-credit">
      David Dunn. Wilderness as Reentrant Form: Thoughts on the Future of
      Electronic Art and Nature. Leonardo, (4):377, 1988.
    </em>

      <notes>
      * Composer and artist, David Dunn proposes that communication and art technologies can serve as "prostheses" to
      connect people with wilderness experiences, viewing this as essential since not everyone can access natural spaces
      directly.
      * Sounds Aware exemplifies technology as a "prosthesis" for experiencing wilderness by using smartphones to
      connect users with natural soundscapes through sound walks, active listening, and decentralized sharing. The app
      focuses on restoring attention and fostering ecological awareness by helping users overcome "numbed ears" and
      rediscover natural sounds in their environment. It transforms survey data about restorative experiences into
      shareable sonifications, creating a collective tool for deeper engagement with nature.
      * Environmental artists like Truax, Westerkamp, and Barclay use sound art and interactive technology to raise
      ecological awareness and encourage sustainable behavior through direct engagement
      * While these technological prostheses don't replace direct nature experiences, they can enhance environmental
      understanding, shift perceptions, and motivate conservation efforts
    </notes>
      <div class="slide-count"></div>

    </div>

    <div class="layout">
      <img src="images/sounds-aware-v2/ui-1.png" alt=""/>

      <notes></notes>
      <div class="slide-count"></div>

    </div>

    <div class="layout">
      <img src="images/sounds-aware-v2/ui-2.png" alt=""/>

      <notes>
      * The app focuses on restoration of attention and ecological awareness by encouraging mindful listening and
      outdoor
      experiences
    </notes>
      <div class="slide-count"></div>

    </div>

    <div>
    Coming soon to AT Protocol (aka Bluesky)

    <notes>
      I have plans to bring this back in a similar or slightly different form and release it on AT Protocol, the system
      that runs Bluesky.
    </notes>
    </div>

    <!-- immaterial.cloud -->
    <div class="layout"
    style="grid-template-rows: repeat(4, minmax(0, 1fr)); grid-template-columns: repeat(6, 1fr); gap: 10px;">
      <!-- Large hero image takes up most of the left side -->
      <div style="grid-row: 1 / 4; grid-column: 1 / 4;">
        <img src="images/immaterial.png"/>
      </div>

      <!-- Title and descriptive text on the right -->
      <div style="grid-row: 1 / 2; grid-column: 4 / 7;">
        <span class="underline">immaterial.cloud</span>
      </div>

      <!-- Exhibition details -->
      <div style="grid-row: 3 / 4; grid-column: 4 / 7;">
      Collaborative Sound Art
    </div>

      <!-- Footer information spans full width -->
      <div style="grid-row: 4 / 5; grid-column: 1 / 3;">
        <span class="year">2020</span>
      </div>
      <div style="grid-row: 4 / 5; grid-column: 3 / 7;">
      peer-to-peer networking
    </div>

      <notes>
      * For this project, I revisited the concept of collaborative music-making with smartphones, this time exploring
      the
      use of the phone's camera as a trigger for changes in sound.
      * Networked smartphones form a temporary musical composition that could be set up anywhere, activating sound by
      flipping phones upward to allow the camera to
      detect movement.
      * “Immaterial.Cloud: Using Peer-to-Peer Technologies for Music.” In Proceedings of the Web Audio Conference.
      Barcelona, Spain, 2021.
    </notes>
      <div class="slide-count"></div>

    </div>

    <div class="layout" style="grid-template-rows: 75% 25%">
      <img src="images/immaterialcloud2.png" alt="immaterial.cloud"/>
      <div>Participants interacting with the work</div>
      <notes>
      ## Tech and Interaction

      * Users interact through motion (tracked by phone cameras), which triggers shared sound changes across connected
      devices
      * each device is assigned one of four presets
      using granular synthesis

    </notes>
      <div class="slide-count"></div>

    </div>

    <div class="layout">
      <img src="images/immaterialcloud/qi5jxtMLvuyjoAfMFJ6onDzEUQptFfu8cggWfDfms3Q.png" alt=""/>

      <notes>
      * a closeup image of the setup screen
    </notes>
      <div class="slide-count"></div>

    </div>

    <div>
      <iframe title="vimeo-player" class="responsive-iframe azyload" src="https://player.vimeo.com/video/414630388"
      frameborder="0" allowfullscreen></iframe>

      <notes>
      a short demo of myself using the app
    </notes>
      <div class="slide-count"></div>

    </div>

    <!-- Resonant Landscapes -->
    <div class="layout"
    style="display: grid; grid-template-rows: repeat(4, 1fr); grid-template-columns: repeat(6, 1fr); gap: 10px;">
      <!-- Central image -->
      <div style="grid-row: 2 / 4; grid-column: 2 / 5;">
        <img src="images/frozen-lake.jpeg" style="width: 100%; height: 100%;" alt="Featured image"/>
      </div>

      <!-- Surrounding text -->
      <div style="grid-row: 1 / 2; grid-column: 1 / 7;">
        <span class="underline">Resonant Landscapes</span>
      </div>
      <div style="grid-row: 2 / 4; grid-column: 1 / 2;">
        <span class="year">2023-Present</span>
      </div>
      <div style="grid-row: 2 / 4; grid-column: 5 / 7;">Locative Sound Art</div>
      <div style="grid-row: 4 / 5; grid-column: 1 / 3;">Ambisonic Field Recording</div>
      <div style="grid-row: 4 / 5; grid-column: 5 / 7;">GPS/Gyroscope</div>

      <notes>
      * Resonant Landscapes is my most recent work, and it builds on the concepts explored in my previous projects.
      * The piece uses ambisonic field recordings to create an immersive sound environment that responds to the
      listener's movement through space.
      * By integrating GPS and gyroscope data from smartphones, the work transforms the listener's
      surroundings into a dynamic, interactive soundscape, inviting them to explore the sonic possibilities of their
      environment.
      * Carson, Tate, and Carter Gordon. “Resonant Landscapes.” In Audio Mostly 2024 - Explorations in Sonic Cultures,
      525–32. Milan Italy: ACM, 2024. https://doi.org/10.1145/3678299.3678354.
    </notes>
      <div class="slide-count"></div>

    </div>

    <div class="layout" style="grid-template-rows: 75% 25%">
      <img src="images/rl-screenshots/sd-state-parks.png">
      <div>South Dakota State Parks</div>
      <div class="slide-count"></div>

      <notes>
      * You can see in this picture all of the state parks we recorded at.
      * Carter was integral to this project, as I
      would
      not have been able to record all of these locations without his help.
    </notes>
    </div>

    <div class="layout" style="grid-template-rows: 75% 25%">
      <img src="images/rl-screenshots.png" alt="">

      <div>User Interactions</div>

      <notes>
      * Resonant Landscapes' audience webpage provides an interactive campus map with marked "listening spots" that
      correspond to state park locations
      * Users experience audio playback within 15-meter radius zones, with volume increasing as they approach centers
      * Visual feedback includes falling leaves animation that speeds up with proximity
      * The app uses smartphone sensors for body-oriented tracking, letting users change soundscape orientation by
      turning physically
    </notes>
      <div class="slide-count"></div>

    </div>

    <div>

      <em>
        <strong>Resonant Landscapes</strong>
      </em> creates a <strong>hybrid place</strong>, merging natural
    soundscapes with urban spaces through <strong>ambisonic audio</strong> and GPS technology.

    <notes>

      ## Creating a Hybrid Place
      * The South Dakota state parks are onto DSU campus, creating a scaled, walkable geography.
      * Because the app triggers field recordings at specific GPS coordinates,
      it blends natural soundscapes with real-time urban environments, creating a hybrid place.
      * Encourages embodied listening—users turn their bodies to shift sonic perspective.
      * Emphasizes non-representational sound to foster deeper immersion and imagination.

      ## Conceptual Framework
      * Informed by sound art, soundwalking, and soundscape studies.
      * Re-situates nature sounds within an urban context to highlight their ecological and cultural significance.
      * Investigates the interplay between sound, place, and perception.

      ## Experiential Aims
      * Designed to induce reflection and contemplative awareness.
      * Invites listeners to reimagine their relationship with everyday spaces through immersive, responsive audio.
      * Challenges traditional boundaries of music and art by using spatial sound as an experiential medium.

    </notes>
      <div class="slide-count"></div>
    </div>

    <div class="layout" style="grid-template-rows: 75% 25%">
      <img src="images/rl-screenshots/me-carter.png" alt="">

      <div>Student Research</div>

      <notes>
      * Resonant Landscapes was developed in collaboration with a student at Dakota State University.
      * The project provided an opportunity to engage with cutting-edge technologies and explore the creative
      possibilities of locative sound art.
      * Through their research and experimentation, my student contributed to the development of the app and helped
      shape its features.
    </notes>
      <div class="slide-count"></div>

    </div>

    <!--
    <div
    style="display: grid; grid-template-rows: repeat(6, 1fr); grid-template-columns: repeat(6, 1fr); gap: 50px; height: 100vh; padding: 80px; width: 100%; place-items: center; align-items: center;">

    
      <div style="grid-row: 2 / 3; grid-column: 1 / 7; display: flex; align-items: center; justify-content: center;">
        <span class="border"
        style="font-size: 5.5vw; padding: 40px; transform: rotate(-2deg); border-width: 8px; border-style: solid; width: max-content;">
        Technical Details
      </span>
      </div>

      <div style="grid-row: 4; grid-column: 1 / 3; display: flex; align-items: center; justify-content: center;">
        <span style="font-size: 2.5vw; font-weight: bold; border: 4px solid black; padding: 20px;">
        Core Tech & Sensors
      </span>
      </div>

      <div
      style="grid-row: 5; grid-column: 3 / 7; border-left: 10px solid black; padding-left: 50px; display: flex; align-items: center;">
        <span style="font-size: 2.5vw;">Core Audio OctoMic & Spatial Audio SDK &nbsp;&nbsp;&nbsp;&nbsp;</span>
      </div>

      <div
      style="grid-row: 6; grid-column: 3 / 7; border-left: 10px solid black; padding-left: 50px; display: flex; align-items: center;">
        <span style="font-size: 2.5vw;">React, Tailwind CSS, & Smartphone Sensors</span>
      </div>

      <notes>
      # Technical Details

      ## **Core Technologies**
      * **Core Audio OctoMic** for **2nd-order ambisonic recording**.
      * **Resonance Audio SDK** for **spatial audio processing**.

      ## **Web Tech & Sensors**
      * Built with **React & Tailwind CSS** for a lightweight, flexible UI.
      * Utilizes **smartphone GPS, gyroscope, and accelerometer** for body-oriented listening.

      ## **Key Libraries**
      * **Omnitone**: Ambisonic audio handling.
      * **Three.js**: 3D spatial calculations.
      * **Turf.js**: Geospatial data analysis.
      * **rLayers**: Interactive map rendering.

      ## **Design Principles**
      * **Frugal innovation**: Maximizing existing smartphone sensors & web-based technology.
      * **Lightweight & scalable**: Designed for accessibility on mobile devices.
      * **Real-time interaction**: Uses GPS & motion tracking for dynamic experiences.

    </notes>
    </div>
-->
    <div class="layout" style="grid-template-rows: 75% 25%">
      <img src="images/rl-screenshots/uni-mi.png">
      <div>Resonant Landscapes @ UniMi</div>
      <div class="slide-count"></div>
      <notes>
      * As locative media art rather than site-specific art, Resonant Landscapes can be deployed anywhere by mapping
      state park coordinates onto new locations
    </notes>
    </div>

    <div class="layout">

    Resonant Landscapes Concert

    <notes>
      * In addition to using the ambisonic recordings in the Resonant Landscapes app, DSU faculty and students composed
      works that premiered during a public concert at the Madison Area Arts Council.
    </notes>
      <div class="slide-count"></div>

    </div>

    <div class="layout">

      <img src="images/rl-concert/landscape-poster.png" alt="">

      <notes>
      * In addition to using the ambisonic recordings in the Resonant Landscapes app, DSU faculty and students composed
      works that premiered during a public concert at the Madison Area Arts Council.
    </notes>
      <div class="slide-count"></div>

    </div>

    <div style="display: flex; justify-content: space-between;">

      <img src="images/rl-concert/me.png" alt="" style="width: 48%;">
      <img src="images/rl-concert/daniel.png" alt="" style="width: 48%;">

      <notes>
      * In addition to using the ambisonic recordings in the Resonant Landscapes app, DSU faculty and students composed
      works that premiered during a public concert at the Madison Area Arts Council.
    </notes>
      <div class="slide-count"></div>

    </div>

    <div class="layout" style="display: flex; justify-content: center; align-items: center; flex-direction: column;">

      <img src="images/rl-concert/kayla.png" alt="" style="max-width: 100%; height: auto; margin: 0 auto;">

      <notes>
      * In addition to using the ambisonic recordings in the Resonant Landscapes app, DSU faculty and students composed
      works
      that premiered during a public concert at the Madison Area Arts Council.
    </notes>
      <div class="slide-count"></div>

    </div>

    <div class="layout" style="display: flex; justify-content: center; align-items: center; flex-direction: column;">

      <img src="images/rl-concert/jacob.png" alt="" style="max-width: 100%; height: auto; margin: 0 auto;">

      <notes>
      * In addition to using the ambisonic recordings in the Resonant Landscapes app, DSU faculty and students composed
      works
      that premiered during a public concert at the Madison Area Arts Council.
    </notes>
      <div class="slide-count"></div>

    </div>

    <div
    style="display: grid; grid-template-rows: repeat(4, minmax(0, 1fr)); grid-template-columns: repeat(6, 1fr); gap: 10px; height: 100vh;">
      <!-- Dominant visual element -->
      <div style="grid-row: 1 / 4; grid-column: 1 / 4;">
        <span class="underline">Veins of</span>
      </div>
      <div style="grid-row: 2 / 3; grid-column: 1 / 4;">
        <span class="underline">the Earth</span>
      </div>

      <!-- Information block -->
      <div style="grid-row: 3 / 4; grid-column: 4 / 7;">Fixed</div>

      <!-- Footer information -->
      <div style="grid-row: 4 / 5; grid-column: 4/7;">Media</div>
      <div style="grid-row: 4 / 5; grid-column: 1;">
        <span class="year">2024</span>
      </div>

      <!-- Soundcloud Player -->
      <div class="soundcloud-embed" style="grid-row: 1 / 3; grid-column: 4 / 7; align-self: center;">
        <iframe width="100%" height="166" scrolling="no" frameborder="no" allow="autoplay"
        src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/1833817539&color=%233c7494&auto_play=false&hide_related=false&show_comments=true&show_user=true&show_reposts=false&show_teaser=true"></iframe>
      </div>
      <notes>
      * The work I composed for this concert was a multi-channel fixed media piece, “Veins of the Earth,” which explores
      geophonic and biophonic sounds to evoke a sense of connection between natural environments and the life they
      sustain.
    </notes>
      <div class="slide-count"></div>

    </div>

    <div>
    Current Research
  </div>

    <div
    style="display: grid; grid-template-rows: repeat(6, 1fr); grid-template-columns: repeat(6, 1fr); gap: 50px; height: 100vh; padding: 80px; width: 100%; place-items: center; align-items: center;">

      <!-- Main Title -->
      <div style="grid-row: 2 / 3; grid-column: 1 / 7; display: flex; align-items: center; justify-content: center;">
        <span class="border"
        style="font-size: 5.5vw; padding: 40px; border-width: 8px; border-style: solid; width: max-content;">
        ReaMatch
      </span>
      </div>

      <!-- Subtitle -->
      <div style="grid-row: 3 / 4; grid-column: 1 / 7; display: flex; align-items: center; justify-content: center;">
        <span style="font-size: 3vw; font-weight: bold; text-transform: uppercase; letter-spacing: 2px;">
        AI-Powered Sound Matching for REAPER
      </span>
      </div>

      <!-- Key Themes Section -->
      <div style="grid-row: 4; grid-column: 1 / 3; display: flex; align-items: center; justify-content: center;">
        <span style="font-size: 2.5vw; font-weight: bold; border: 4px solid black; padding: 20px;">
        Machine Learning for Sound Discovery
      </span>
      </div>

      <div
      style="grid-row: 5; grid-column: 3 / 7; border-left: 10px solid black; padding-left: 50px; display: flex; align-items: center;">
        <span style="font-size: 2.5vw;">Find Perceptually Similar Sounds Instantly</span>
      </div>

      <div
      style="grid-row: 6; grid-column: 3 / 7; border-left: 10px solid black; padding-left: 50px; display: flex; align-items: center;">
        <span style="font-size: 2.5vw;">Seamless Integration with REAPER
        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span>
      </div>

      <notes>
      ## **Key Themes**
      * **Machine Learning for Sound Discovery**
      * Uses **Google’s VGGish model** to **analyze & match** sounds based on deep audio feature extraction.
      * Converts sounds into **128-dimensional embeddings** for **precise similarity searches**.

      ## **Find Perceptually Similar Sounds Instantly**
      * Extracts **onset strength, spectral centroid, sustain, reverb characteristics**, and more.
      * Uses **cosine similarity & feature-based ranking** to match sounds in the user's sample library.
      * Preprocessed caching enables **fast searching**.

      ## **Seamless Integration with REAPER**
      * **Adds alternative takes** to media items for quick auditioning.
      * **Customizable search parameters** via user-friendly GUI.
      * Fully embedded within **REAPER’s workflow**, enhancing efficiency.

    </notes>

    </div>

    <div
    style="display: grid; grid-template-rows: repeat(6, 1fr); grid-template-columns: repeat(6, 1fr); gap: 50px; height: 100vh; padding: 80px; width: 100%; place-items: center; align-items: center;">

      <!-- Main Title -->
      <div style="grid-row: 2 / 3; grid-column: 1 / 7; display: flex; align-items: center; justify-content: center;">
        <span class="border"
        style="font-size: 5.5vw; padding: 40px; border-width: 8px; border-style: solid; width: max-content;">
        Water’s Sonic Signatures
      </span>
      </div>

      <!-- Subtitle -->
      <div style="grid-row: 3 / 4; grid-column: 1 / 7; display: flex; align-items: center; justify-content: center;">
        <span style="font-size: 3vw; font-weight: bold; text-transform: uppercase; letter-spacing: 2px;">
        Computational Sound Studies & Ecological Awareness in Tarkovsky’s Films
      </span>
      </div>

      <!-- Key Themes Section -->
      <div style="grid-row: 4; grid-column: 1 / 3; display: flex; align-items: center; justify-content: center;">
        <span style="font-size: 2.5vw; font-weight: bold; border: 4px solid black; padding: 20px;">
        Water as Cinematic & Ecological Motif
      </span>
      </div>

      <div
      style="grid-row: 5; grid-column: 3 / 7; border-left: 10px solid black; padding-left: 50px; display: flex; align-items: center;">
        <span style="font-size: 2.5vw;">Analyzing Sound in Solaris, Stalker, & Nostalghia</span>
      </div>

      <div
      style="grid-row: 6; grid-column: 3 / 7; border-left: 10px solid black; padding-left: 50px; display: flex; align-items: center;">
        <span style="font-size: 2.5vw;">Computational Listening: MFCCs, Reverb, & Timbre</span>
      </div>

      <notes>
      # Water’s Sonic Signatures: Computational Sound Studies & Ecological Awareness in Tarkovsky’s Films

      ## Key Themes

      ### Water as a Sonic & Ecological Motif
      * Tarkovsky’s films use water beyond atmosphere, shaping narrative temporality, materiality, and ecological
      consciousness.
      * Flow, decay, and renewal inform existential and emotional shifts in *Solaris*, *Stalker*, and *Nostalghia*.

      ### Computational Sound Analysis
      * Mel-frequency cepstral coefficients (MFCCs) capture the textural depth of water.
      * Spectral centroid, bandwidth, and onset detection analyze timbre and rhythmic structures.
      * Reverb modeling highlights how Tarkovsky blurs physical and cinematic space through sound.

      ### Ecological Soundscapes & Media Awareness
      * Tarkovsky’s sonic environments create an ecological listening experience.
      * Computational methods reveal patterns influencing ecological perception.
      * This approach provides a new framework for studying media soundscapes in the context of climate and
      environmental
      crises.

    </notes>
    </div>

    <div
    style="display: grid; grid-template-rows: repeat(6, 1fr); grid-template-columns: repeat(6, 1fr); gap: 50px; height: 100vh; padding: 80px; width: 100%; place-items: center; align-items: center;">

      <!-- Archive title with strong visual presence -->
      <div style="grid-row: 2 / 3; grid-column: 1 / 7; display: flex; align-items: center; justify-content: center;">
        <span class="border"
        style="font-size: 6vw; padding: 40px; border-width: 10px; border-style: solid; width: max-content;">
        South Dakota Sound Archive
      </span>
      </div>

      <!-- Year with brutalist styling -->
      <div style="grid-row: 3 / 4; grid-column: 1 / 3; display: flex; align-items: center; justify-content: center;">
        <span class="year" style="font-size: 5vw; padding: 30px 60px; display: inline-block; border: 6px solid black;">
        2025
      </span>
      </div>

      <!-- Key aspects with asymmetrical layout -->
      <div
      style="grid-row: 4; grid-column: 3 / 7; border-left: 12px solid black; padding-left: 50px; display: flex; align-items: center;">
        <span style="font-size: 4vw;">Student Research Collaboration</span>
      </div>

      <div
      style="grid-row: 5; grid-column: 3 / 7; border-left: 12px solid black; padding-left: 50px; display: flex; align-items: center;">
        <span style="font-size: 4vw;">Community Sound Engagement</span>
      </div>
      <notes>
      * My future research focuses on creating the DSU Digital Sound Archive, a project designed to capture the
      ecological soundscapes and cultural heritage of South Dakota and nearby regions.
      * By integrating advanced field recording techniques and metadata, the archive will support interdisciplinary
      research across sound studies, ecology, and digital arts.
      * A key component of the project is the Resonant Landscapes app, which uses GPS technology to overlay
      soundscapes onto physical locations, enhancing public engagement and ecological awareness.
      * This initiative aligns with DSU's mission to expand research opportunities and foster collaboration across
      disciplines.
    </notes>
      <div class="slide-count"></div>

    </div>

    <div>
      <div>Bibliography</div>
      <br/>
      <div class="csl-bib-body" style="line-height: 1.35; margin-left: 2em; text-indent:-2em;">
        <div class="csl-entry">Carson, Tate. “A More Perfect Union: Composition with Audience-Controlled Smartphone
        Speaker Array and Evolutionary Computer Music.” In <i>Proceedings of the Web Audio Conference</i>. Berlin,
        Germany, 2018.</div>
        <span class="Z3988"
        title="url_ver=Z39.88-2004&amp;ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fzotero.org%3A2&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=proceeding&amp;rft.atitle=A%20more%20perfect%20union%3A%20Composition%20with%20audience-controlled%20smartphone%20speaker%20array%20and%20evolutionary%20computer%20music&amp;rft.btitle=Proceedings%20of%20the%20Web%20audio%20Conference&amp;rft.place=Berlin%2C%20Germany&amp;rft.aufirst=Tate&amp;rft.aulast=Carson&amp;rft.au=Tate%20Carson&amp;rft.date=2018"></span>
        <div class="csl-entry">———. “Immaterial.Cloud: Using Peer-to-Peer Technologies for Music.” In <i>Proceedings of
          the Web Audio Conference</i>. Barcelona, Spain, 2021.</div>
        <span class="Z3988"
        title="url_ver=Z39.88-2004&amp;ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fzotero.org%3A2&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=proceeding&amp;rft.atitle=immaterial.cloud%3A%20Using%20peer-to-peer%20technologies%20for%20music&amp;rft.btitle=Proceedings%20of%20the%20Web%20audio%20Conference&amp;rft.place=Barcelona%2C%20Spain&amp;rft.aufirst=Tate&amp;rft.aulast=Carson&amp;rft.au=Tate%20Carson&amp;rft.date=2021"></span>
        <div class="csl-entry">———. “Mesh Garden: A Creative-Based Musical Game for Participatory Musical Performance.” In
        <i>Proceedings of the International Conference on New Interfaces for Musical Expression</i>, 339–42. Porto
        Alegre, Brazil, 2019.
      </div>
        <span class="Z3988"
        title="url_ver=Z39.88-2004&amp;ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fzotero.org%3A2&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=proceeding&amp;rft.atitle=Mesh%20Garden%3A%20A%20creative-based%20musical%20game%20for%20participatory%20musical%20performance.&amp;rft.btitle=Proceedings%20of%20the%20International%20Conference%20on%20New%20Interfaces%20for%20Musical%20Expression&amp;rft.place=Porto%20Alegre%2C%20Brazil&amp;rft.aufirst=Tate&amp;rft.aulast=Carson&amp;rft.au=Tate%20Carson&amp;rft.date=2019&amp;rft.pages=339-342&amp;rft.spage=339&amp;rft.epage=342"></span>
        <div class="csl-entry">———. “Musical Sonification of Hurricane Katrina and Its Aftermath.” Master, Mills College,
        2017.</div>
        <span class="Z3988"
        title="url_ver=Z39.88-2004&amp;ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fzotero.org%3A2&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Adissertation&amp;rft.title=Musical%20sonification%20of%20hurricane%20katrina%20and%20its%20aftermath&amp;rft.aufirst=Tate&amp;rft.aulast=Carson&amp;rft.au=Tate%20Carson&amp;rft.date=2017"></span>
        <div class="csl-entry">———. “On Ecocomposition: An Interview with Damián Keller.” <i>Journal of Digital Media
          &amp; Interaction</i> 3, no. 5 (2020): 133–42.</div>
        <span class="Z3988"
        title="url_ver=Z39.88-2004&amp;ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fzotero.org%3A2&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.atitle=On%20ecocomposition%3A%20An%20interview%20with%20Dami%C3%A1n%20Keller&amp;rft.jtitle=Journal%20of%20Digital%20Media%20%26%20Interaction&amp;rft.volume=3&amp;rft.issue=5&amp;rft.aufirst=Tate&amp;rft.aulast=Carson&amp;rft.au=Tate%20Carson&amp;rft.date=2020&amp;rft.pages=133%E2%80%93142&amp;rft.spage=133&amp;rft.epage=142"></span>
        <div class="csl-entry">———. “Philosophical Underpinnings of Environmental Music.” In <i>Proceedings of the
          International Computer Music Conference</i>. Daegu, Korea, 2018.</div>
        <span class="Z3988"
        title="url_ver=Z39.88-2004&amp;ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fzotero.org%3A2&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=proceeding&amp;rft.atitle=Philosophical%20Underpinnings%20of%20Environmental%20Music.&amp;rft.btitle=Proceedings%20of%20the%20International%20Computer%20Music%20Conference&amp;rft.place=Daegu%2C%20Korea&amp;rft.aufirst=Tate&amp;rft.aulast=Carson&amp;rft.au=Tate%20Carson&amp;rft.date=2018"></span>
        <div class="csl-entry">———. “Sounds Aware: A Mobile App for Raising Awareness of Environmental Sound.” In
        <i>Proceedings of the Web Audio Conference</i>. Trondheim, Norway, 2019.
      </div>
        <span class="Z3988"
        title="url_ver=Z39.88-2004&amp;ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fzotero.org%3A2&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=proceeding&amp;rft.atitle=Sounds%20Aware%3A%20A%20Mobile%20App%20for%20Raising%20Awareness%20of%20Environmental%20Sound&amp;rft.btitle=Proceedings%20of%20the%20Web%20audio%20Conference&amp;rft.place=Trondheim%2C%20Norway&amp;rft.aufirst=Tate&amp;rft.aulast=Carson&amp;rft.au=Tate%20Carson&amp;rft.date=2019-12-04"></span>
        <div class="csl-entry">———. “Systems Thinking and Environmental Interaction in the Work of Tomás Saraceno and
        David Dunn.” In <i>Proceedings of the International Computer Music Conference</i>. New York, 2019.</div>
        <span class="Z3988"
        title="url_ver=Z39.88-2004&amp;ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fzotero.org%3A2&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=proceeding&amp;rft.atitle=Systems%20Thinking%20and%20Environmental%20Interaction%20in%20the%20Work%20of%20Tom%C3%A1s%20Saraceno%20and%20David%20Dunn&amp;rft.btitle=Proceedings%20of%20the%20International%20Computer%20Music%20Conference&amp;rft.place=New%20York&amp;rft.aufirst=Tate&amp;rft.aulast=Carson&amp;rft.au=Tate%20Carson&amp;rft.date=2019"></span>
        <div class="csl-entry">———. “Teaching Video Game Sound: Balancing Technical Know-How with Sonic Creativity.” Talk
        presented at the 2023 ATMI/CMS National Conference, Miami, Florida, 2023. <a
          href="https://www.atmimusic.com/conferences/2023-atmi-cms-national-convention/">https://www.atmimusic.com/conferences/2023-atmi-cms-national-convention/</a>.
      </div>
        <span class="Z3988"
        title="url_ver=Z39.88-2004&amp;ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fzotero.org%3A2&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Adc&amp;rft.type=presentation&amp;rft.title=Teaching%20Video%20Game%20Sound%3A%20Balancing%20Technical%20Know-How%20with%20Sonic%20Creativity&amp;rft.rights=All%20rights%20reserved&amp;rft.identifier=https%3A%2F%2Fwww.atmimusic.com%2Fconferences%2F2023-atmi-cms-national-convention%2F&amp;rft.aufirst=Tate&amp;rft.aulast=Carson&amp;rft.au=Tate%20Carson&amp;rft.date=2023"></span>
        <div class="csl-entry">———. “Using Distributed Technology to Make Music in the Time of the Attention Economy.”
        Phd, Louisiana State University and Agricultural &amp; Mechanical College, 2021.</div>
        <span class="Z3988"
        title="url_ver=Z39.88-2004&amp;ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fzotero.org%3A2&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Adissertation&amp;rft.title=Using%20distributed%20technology%20to%20make%20music%20in%20the%20time%20of%20the%20attention%20economy&amp;rft.aufirst=Tate&amp;rft.aulast=Carson&amp;rft.au=Tate%20Carson&amp;rft.date=2021"></span>
        <div class="csl-entry">Carson, Tate, and Carter Gordon. “Resonant Landscapes.” In <i>Audio Mostly 2024 -
          Explorations in Sonic Cultures</i>, 525–32. Milan Italy: ACM, 2024. <a
          href="https://doi.org/10.1145/3678299.3678354">https://doi.org/10.1145/3678299.3678354</a>.</div>
        <span class="Z3988"
        title="url_ver=Z39.88-2004&amp;ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fzotero.org%3A2&amp;rft_id=info%3Adoi%2F10.1145%2F3678299.3678354&amp;rft_id=urn%3Aisbn%3A9798400709685&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=proceeding&amp;rft.atitle=Resonant%20Landscapes&amp;rft.btitle=Audio%20Mostly%202024%20-%20Explorations%20in%20Sonic%20Cultures&amp;rft.place=Milan%20Italy&amp;rft.publisher=ACM&amp;rft.aufirst=Tate&amp;rft.aulast=Carson&amp;rft.au=Tate%20Carson&amp;rft.au=Carter%20Gordon&amp;rft.date=2024-09-18&amp;rft.pages=525-532&amp;rft.spage=525&amp;rft.epage=532&amp;rft.isbn=9798400709685&amp;rft.language=en"></span>
        <div class="csl-entry">Marasco, Anthony T, Tate Carson, and Matthew A Bardin. “Designing Collaborative and
        Mediated Experiences with Networked Circuit-Bent Devices.” In <i>Proceedings of the Sound, Image and Interaction
          Design Symposium</i>, 2020.</div>
        <span class="Z3988"
        title="url_ver=Z39.88-2004&amp;ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fzotero.org%3A2&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=proceeding&amp;rft.atitle=Designing%20Collaborative%20and%20Mediated%20Experiences%20with%20Networked%20Circuit-Bent%20Devices&amp;rft.btitle=Proceedings%20of%20the%20Sound%2C%20Image%20and%20Interaction%20Design%20Symposium&amp;rft.aufirst=Anthony%20T&amp;rft.aulast=Marasco&amp;rft.au=Anthony%20T%20Marasco&amp;rft.au=Tate%20Carson&amp;rft.au=Matthew%20A%20Bardin&amp;rft.date=2020"></span>
      </div>
    </div>

    <div class=layout style='grid-template-columns: 50% 50%;'>
      <div>Questions?</div>
      <div>tatecarson.com tate.carson@pm.me</div>
      <div class="slide-count"></div>

    </div>

  </body>

</html>