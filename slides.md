---
theme: neversink
colorSchema: light
title: Research and Creative Work
neversink_string: "Tate Carson, PhD"
layout: cover
color: navy
---

# Research and Creative Work

**From Participatory Mobile Music to Locative Sound Art**

Tate Carson, PhD
_Assistant Professor of Digital Sound Design_

<!--
Introduction; mobile music and locative sound art with smartphones.
-->

---
layout: top-title
color: sky-light
align: l
---

:: title ::

# The Smartphone as Artistic Platform

:: content ::

<div class="flex flex-col gap-8 mt-8">

<div class="flex items-center gap-8 ml-48">
<span class="text-2xl font-bold border-2 border-current px-6 py-3 whitespace-nowrap">UBIQUITY</span>
<span class="text-xl">Open access</span>
</div>

<div class="flex items-center gap-8 ml-8">
<span class="text-2xl font-bold border-2 border-current px-6 py-3 whitespace-nowrap">SENSORS</span>
<span class="text-xl">GPS, gyroscope, microphone integration</span>
</div>

<div class="flex items-center gap-8 ml-28">
<span class="text-2xl font-bold border-2 border-current px-6 py-3 whitespace-nowrap">NETWORKS</span>
<span class="text-xl">Distributed and collaborative music-making</span>
</div>

</div>

<!--
A few things that make smartphones particularly interesting for music and sound art are their ubiquity, many people already have one in their pocket, the sensors that come with them, like GPS, gyroscope, and microphone, and the networks that they can connect to, allowing for the creation of collaborative digital musical experiences.
-->

---
layout: default
---

# Research Overview

| Work | Year |
|------|------|
| And the water receded | 2017 |
| A more perfect union | 2017 |
| Mesh Garden | 2018 |
| Sounds Aware | 2019-2021 |
| immaterial.cloud | 2020 |
| Resonant Landscapes | 2023-Present |

<!--
I'll give an overview of the progression of my work over the past few years. These works have explored different aspects of mobile music and locative sound art, and have built on each other to create a body of work that explores the potential of the smartphone as an artistic platform. [PACING: Past works (next ~20 slides) should take ~25 min total. Keep momentum — the current/future work is what the committee wants to hear most.]
-->

---
layout: side-title
color: cyan-light
align: rm-lm
titlewidth: is-4
---

:: title ::

# And the water receded
**2017**

:: content ::

**Sonification of Hurricane Katrina**

Networked Animated Notation

<img src="/images/and-the-water.jpg" class="w-60 mt-4 rounded" />

Stepping Stone to Participatory Works &rarr;

<!--
And the water receded is a musical piece that sonifies Hurricane Katrina data for three performers and electronics, condensing the storm's timeline from formation to landfall. The work stems from my personal hurricane experiences and uses animated smartphone-based notation to synchronize performers with electronics.

"Musical Sonification of Hurricane Katrina and Its Aftermath." Master, Mills College, 2017.
-->

---
layout: iframe
url: https://www.youtube.com/embed/es_4M9t9K-4?si=N1-zD5QbFOD85nhW&start=330
---

<!--
A performance at Mills College in 2017. [VIDEO: Play ~2:00 starting at 5:30 — the climax section. Skip ahead if needed to stay on time.]
-->

---
layout: side-title
color: amber-light
align: lm-lm
titlewidth: is-4
---

:: title ::

# A more perfect union
**2017**

:: content ::

<img src="/images/ampu.png" class="w-80 mb-4 rounded" />

**Direct Audience Control**

Smartphone Speaker Array

<!--
A More Perfect Union was conceived as a direct response to the limitations of And the Water Receded. Utilizing a smartphone speaker array, the work provided an immersive and interactive experience for the audience. Guided by audience evaluations, melodies evolved through a genetic algorithm.

Carson, Tate. "A More Perfect Union: Composition with Audience-Controlled Smartphone Speaker Array and Evolutionary Computer Music." In Proceedings of the Web Audio Conference. Berlin, Germany, 2018.
-->

---
layout: iframe
url: https://player.vimeo.com/video/267062963
---

<!--
This is a performance version of the work that took place at LSU Museum of Art on March 4, 2018. [VIDEO: Play ~1:30 — enough to show the audience interaction and smartphone speaker array in action.]
-->

---
layout: section
color: amber
---

# Breaking the Audience / Performer Divide

From passive listeners to active creators

<!--
The audience transitions from passive listeners to active creators in A more perfect union, with all participants serving dual roles as both audience and performers. Participation requires no musical expertise - audience members simply express preferences by choosing to listen to or skip melodies. The work functions as a conceptual experiment focused on collective creation.
-->

---
layout: image
image: /images/amoreperfectunion/League_FtM_perf.jpg
---

<div class="absolute bottom-4 left-4 bg-black/80 text-white p-4 rounded max-w-lg">

The League of Automatic Music Composers (Perkis, Horton, and Bischoff, left to right) performing at Ft. Mason, San Francisco 1981.

<span class="text-xs">photo: Peter Abramowitsch</span>
</div>

<!--
A precursor to this concept of distributed control of a composition can be found in the early computer networked music groups The League of Automatic Music Composers and later The Hub. They created networks of computers that would send messages to other computers to create a rich texture of evolving sounds.
-->

---
layout: image
image: /images/amoreperfectunion/sims-galapagos.jpg
---

<div class="absolute bottom-4 left-4 bg-black/80 text-white p-4 rounded max-w-lg">

Karl Sims' Galapagos (1997)

<span class="text-xs">photo: Ohtaka Takashi</span>
</div>

<!--
Karl Sims' 1997 installation Galapagos consisted of several video screens, each displaying a different virtual organism. The installation allowed spectators to take part in evolving virtual organisms by choosing the amount of time they spent in front of one video screen versus another. The longer a viewer stood in front of a screen, the more he increased the fitness of that virtual organism.
-->

---
layout: side-title
color: emerald-light
align: rm-lm
titlewidth: is-4
---

:: title ::

# Mesh Garden
**2018**

:: content ::

<img src="/images/mesh-garden-2.png" class="w-120 mb-4 rounded" />

**Musical Game** | Gyroscope | Party Music


<!--
Mesh Garden is a participatory music game, using smartphones as speakers/controllers in social settings, where players interact with each other to create ambient music via a web interface. The system enables creative musical interaction through phone orientation and compass heading matching.

"Mesh Garden: A Creative-Based Musical Game for Participatory Musical Performance." NIME, Porto Alegre, Brazil, 2019.
-->

---
layout: iframe
url: https://www.youtube.com/embed/_WQHdGdvO2E
---

<!--
Here's a video of the piece in action. The video shows a group of people playing the game, interacting with each other. [VIDEO: Play ~1:30 — show the social interaction and gyroscope gameplay.]
-->

---
layout: image
image: /images/mesh-garden/Guitar-GH3-hammeron.0.webp
---

<div class="absolute bottom-4 left-4 bg-black/80 text-white p-4 rounded max-w-lg">

**Guitar Hero** - Mesh Garden contrasts with mimicry games like Guitar Hero which recreate existing songs

<span class="text-xs">Photo: polygon.com</span>
</div>

<!--
Mesh Garden contrasts with mimicry games like Guitar Hero which recreate existing songs. Core gameplay involves musical decision-making through phone orientation and player interaction, with mechanics designed for creating new music rather than reproducing predetermined scores. Following Thomas Studley's framework, Mesh Garden meets creative-based game criteria.
-->

---
layout: side-title
color: teal-light
align: lm-lm
titlewidth: is-4
---

:: title ::

# Sounds Aware
**2019 - 2021**

:: content ::

<img src="/images/sounds-aware.png" class="w-120 mb-4 rounded" />

**Locative Audio Sound Art**

An app for sharing sound walks

<!--
After Mesh Garden, I became interested in leveraging the mobility of smartphones to create experiences designed for outdoor environments and walking. This led to Sounds Aware, a locative audio sound art project that fostered a shared experience of the environment through sound.

"Using Distributed Technology to Make Music in the Time of the Attention Economy." PhD, Louisiana State University, 2021.
-->

---
layout: quote
color: teal-light
quotesize: text-xl
authorsize: text-sm
author: "David Dunn. Wilderness as Reentrant Form: Thoughts on the Future of Electronic Art and Nature. Leonardo, (4):377, 1988."
---

"To what extent might the technologies of communication, art and entertainment serve as 'prostheses' that would provide us with experiences of wilderness that would not only enrich our human identity but help us to preserve and expand the domain of the non-human world?"

<!--
Composer and artist David Dunn proposes that communication and art technologies can serve as "prostheses" to connect people with wilderness experiences. Sounds Aware exemplifies technology as a "prosthesis" for experiencing wilderness by using smartphones to connect users with natural soundscapes through sound walks, active listening, and decentralized sharing.
-->

---
layout: default
---

<div class="flex flex-col justify-center items-center h-full">
<img src="/images/sounds-aware-v2/ui-1.png" class="max-h-96 rounded" />

Exploring Walks
</div>

<!--
The discover page lets users browse nearby sound walks. Each walk is a series of stops where the creator answered survey questions about the perceived restorativeness of that place — based on Payne's Perceived Restorativeness Soundscape Scale. Those survey responses drive the sonification you hear when you visit the stop.
-->

---
layout: default
---

<div class="flex flex-col justify-center items-center h-full">
<img src="/images/sounds-aware-v2/ui-2.png" class="max-h-96 rounded" />

Listening to a Walk
</div>

<!--
When you arrive at a stop, the app sonifies the restorativeness data as wind chimes tuned to La Monte Young's Well Tuned Piano tuning. Lower restorativeness scores produce more intense, dissonant chimes; higher scores are calmer and more consonant. Wind and nature samples layer underneath, also mapped to the survey data. All user data is stored on IPFS using decentralized identity — no central server, no attention economy platform.
-->


---
layout: side-title
color: violet-light
align: rm-lm
titlewidth: is-4
---

:: title ::

# immaterial.cloud
**2020**

:: content ::

<img src="/images/immaterial.png" class="w-120 mb-4 rounded" />

**Collaborative Sound Art**

peer-to-peer networking

<!--
For this project, I revisited the concept of collaborative music-making with smartphones, this time exploring the use of the phone's camera as a trigger for changes in sound. Networked smartphones form a temporary musical composition that could be set up anywhere.

"Immaterial.Cloud: Using Peer-to-Peer Technologies for Music." Web Audio Conference, Barcelona, Spain, 2021.
-->

---
layout: default
---

<div class="flex flex-col items-center justify-center h-full">
<img src="/images/immaterialcloud2.png" class="max-h-80 rounded mb-4" />

Participants interacting with the work
</div>

<!--
Users interact through motion (tracked by phone cameras), which triggers shared sound changes across connected devices. Each device is assigned one of four presets using granular synthesis.
-->

---
layout: default
---

<div class="flex flex-col justify-center items-center h-full">
<img src="/images/immaterialcloud/qi5jxtMLvuyjoAfMFJ6onDzEUQptFfu8cggWfDfms3Q.png" class="max-h-96 rounded" />

A closeup of the setup screen, showing the peer-to-peer connection process and preset selection.
</div>

<!--
A closeup image of the setup screen
-->

---
layout: iframe
url: https://player.vimeo.com/video/414630388
---

<!--
A short demo of myself using the app. [VIDEO: Play ~1:30 — show the camera interaction triggering sound changes.]
-->

---
layout: side-title
color: indigo-light
align: rm-lm
titlewidth: is-4
---

:: title ::

# Resonant Landscapes
**2023-Present**

:: content ::

<img src="/images/frozen-lake.jpeg" class="w-80 mb-4 rounded" />

**Locative Sound Art**

Ambisonic Field Recording | GPS/Gyroscope

<!--
Resonant Landscapes is my most recent work, developed in collaboration with undergraduate student Carter Gordon. The piece uses ambisonic field recordings to create an immersive sound environment that responds to the listener's movement through space. By integrating GPS and gyroscope data from smartphones, the work transforms the listener's surroundings into a dynamic, interactive soundscape.

Carson, Tate, and Carter Gordon. "Resonant Landscapes." Audio Mostly 2024, Milan, Italy, ACM, 2024. https://doi.org/10.1145/3678299.3678354.
-->

---
layout: default
---

<div class="flex flex-col justify-center items-center h-full">
<img src="/images/rl-screenshots/sd-state-parks.png" class="max-h-120 rounded" />

South Dakota State Parks
</div>

<!--
You can see in this picture all of the state parks we recorded at. Carter was integral to this project, as I would not have been able to record all of these locations without his help.
-->

---
layout: default
color: indigo
---

<div class="relative h-full">
<h1 class="absolute top-8 left-16 text-8xl font-black tracking-tight">Hybrid</h1>
<h1 class="absolute top-36 right-20 text-8xl font-black tracking-tight">Place</h1>
<p class="absolute bottom-28 left-16 max-w-sm text-xl leading-relaxed"><em>Resonant Landscapes</em> creates a <strong>hybrid place</strong>, merging natural soundscapes with urban spaces</p>
<p class="absolute bottom-12 right-20 max-w-sm text-xl leading-relaxed text-right">through <strong>ambisonic audio</strong> and GPS technology</p>
</div>

<!--
The South Dakota state parks are projected onto DSU campus, creating a scaled, walkable geography. Because the app triggers field recordings at specific GPS coordinates, it blends natural soundscapes with real-time urban environments, creating a hybrid place. Encourages embodied listening. Informed by sound art, soundwalking, and soundscape studies.
-->


---
layout: default
---

<div class="flex flex-col justify-center items-center h-full">
<img src="/images/rl-screenshots.png" class="max-h-120 rounded" />

User Interactions
</div>

<!--
Resonant Landscapes' audience webpage provides an interactive campus map with marked "listening spots" that correspond to state park locations. Users experience audio playback within 15-meter radius zones, with volume increasing as they approach centers. Visual feedback includes falling leaves animation that speeds up with proximity. The app uses smartphone sensors for body-oriented tracking.
-->


---
layout: default
---

<div class="flex flex-col justify-center items-center h-full">
<img src="/images/rl-screenshots/me-carter.png" class="max-h-120 rounded" />

Undergraduate Research — Carter Gordon
</div>

<!--
Resonant Landscapes was developed in collaboration with Carter Gordon, an undergraduate student at Dakota State University. Carter was involved in the full lifecycle of the project — from ambisonic field recording across South Dakota state parks to web development and user testing. He co-authored the peer-reviewed paper published at Audio Mostly 2024 (ACM). This kind of hands-on, publication-track undergraduate research mentoring is central to how I approach working with students.
-->

---
layout: image
image: /images/rl-screenshots/uni-mi.png
---

<div class="absolute bottom-4 left-4 bg-black/80 text-white p-4 rounded">

Resonant Landscapes @ UniMi
</div>

<!--
As locative media art rather than site-specific art, Resonant Landscapes can be deployed anywhere by mapping state park coordinates onto new locations.
-->

---
layout: section
color: indigo
---

# Resonant Landscapes Concert

<!--
In addition to using the ambisonic recordings in the Resonant Landscapes app, DSU faculty and students composed works that premiered during a public concert at the Madison Area Arts Council.
-->

---
layout: default
---

<div class="flex justify-center items-center h-full">
<img src="/images/rl-concert/landscape-poster.png" class="max-h-96 rounded shadow-lg" />
</div>

<!--
The concert was held at the Madison Area Arts Council in spring 2024. I shared the ambisonic field recordings from the state parks with faculty and students and invited them to compose new works using the material. The idea was to extend the project beyond the app and see what other creative responses the recordings could generate.
-->

---
layout: two-cols-title
align: l-cm-cm
---

:: title ::
&nbsp;

:: left ::

<img src="/images/rl-concert/me.png" class="w-full rounded" />

:: right ::

<img src="/images/rl-concert/daniel.png" class="w-full rounded" />

<!--
Here I'm introducing the concert theme. On the right, Daniel, a faculty colleague in music, composed a piece that layered the ambisonic recordings with live electronics. Having faculty from different areas engage with the same source material showed how the project could serve as a shared creative resource across disciplines.
-->

---
layout: image
image: /images/rl-concert/kayla.png
backgroundSize: contain
---

<!--
Kayla, another faculty colleague, performing her composition. Three faculty members and one undergraduate student composed pieces for the concert — each taking a very different approach to the same source recordings.
-->

---
layout: image
image: /images/rl-concert/jacob.png
backgroundSize: contain
---

<!--
Jacob was an undergraduate student who composed a piece using the ambisonic field recordings from the state parks. While Carter was involved in the full Resonant Landscapes project, Jacob's participation in the concert shows how the project created multiple entry points for student engagement — from long-term research collaboration to focused creative work with shared materials.
-->

---
layout: side-title
color: emerald-light
align: rm-lm
titlewidth: is-4
---

:: title ::

# Veins of the Earth
**2024**

:: content ::

**Fixed Media**

Multi-channel piece exploring geophonic and biophonic sounds

<iframe width="100%" height="166" scrolling="no" frameborder="no" allow="autoplay" src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/1833817539&color=%233c7494&auto_play=false&hide_related=false&show_comments=true&show_user=true&show_reposts=false&show_teaser=true"></iframe>

<!--
The work I composed for this concert was a multi-channel fixed media piece, "Veins of the Earth," which explores geophonic and biophonic sounds to evoke a sense of connection between natural environments and the life they sustain. [AUDIO: Play ~1:00 excerpt — let the texture develop before moving to Current Research.]
-->

---
layout: section
color: navy
---

# Current Research

<!--
[PACING CHECK: You should be at roughly the 25-minute mark here. ~20 min remain for MatchLab, Drift, and Future Directions before Q&A at ~45 min. Slow down — this is the most important section.]
-->

---
layout: side-title
color: rose-light
align: rm-lm
titlewidth: is-4
---

:: title ::

# MatchLab
**2025-Present**

:: content ::

**Semantic Sound Search Plugin**

- Search, discover, and modify sounds by description or reference audio
- Runs locally, integrates with DAWs
- Undergraduate research interns: Owen and Calvin (16-week HCI internship)

<!--
MatchLab is a plugin for semantic sound search. It lets sound designers search, discover, and modify sounds based on how they describe them or by similarity to a reference audio. It runs locally and integrates with digital audio workstations. Owen and Calvin, two undergraduate students, are working on a 16-week HCI research internship to ground the design in real professional workflows — conducting competitive analysis, user interviews, and building annotated test datasets. [PACING: Spend ~5 min on this slide and the next — emphasize the student mentorship and publication trajectory.]
-->

---
layout: top-title
color: rose-light
align: l
---

:: title ::

# MatchLab Research Tracks

:: content ::

<div class="grid grid-cols-2 gap-4 mt-4 text-sm">

<div class="border rounded p-3">
<strong>1. Competitive Analysis</strong><br/>
Document existing tools (Soundly, Splice, Sononym, AudioStellar, Freesound, etc.) to identify feature gaps
</div>

<div class="border rounded p-3">
<strong>2. User Research</strong><br/>
Interviews and contextual inquiry with sound designers to build personas and workflow diagrams
</div>

<div class="border rounded p-3">
<strong>3. Test Dataset Curation</strong><br/>
Annotated sound collections with ground-truth similarity judgments for algorithm evaluation
</div>

<div class="border rounded p-3">
<strong>4. Literature Review</strong><br/>
Survey ISMIR, NIME, CHI/UIST, AES on audio similarity, semantic retrieval, and creative tool evaluation
</div>

</div>

<!--
The internship is structured around four research tracks. Competitive analysis systematically documents existing sound search tools to identify feature gaps and opportunities. User research involves interviews and contextual inquiry with sound designers to build personas and workflow diagrams. Test dataset curation builds annotated sound collections with ground-truth similarity judgments. And the literature review surveys academic work on audio similarity, semantic retrieval, and creative tool evaluation.
-->

---
layout: side-title
color: slate-light
align: rm-lm
titlewidth: is-4
---

:: title ::

# Drift
**2025-2026**

:: content ::

<img src="/images/drift/hanging-sculpture.jpeg" class="w-60 mb-4 rounded shadow-lg" />

**Sculptural Sound Art**

White noise machines reimagined as networked, resonant instruments

<!--
Drift is a sculptural sound art project grounded in Mack Hagood's theory of Orphic Media — technologies designed to modify sensory perception and shape experience. White noise machines are a prime example: devices people use to control their sonic environment. Drift reconceptualizes this technology as a platform for creative expression, building sculptures that slowly shift from noise toward emergent musical patterns. The work invites deep listening and asks: what happens when we relinquish sonic self-control? Collaboration with Tim Murray (sculpture and fabrication) and funded through a DSU Faculty Research Initiative grant. [PACING: Spend ~7 min across the three Drift slides — this is funded, in-progress work. Let the fabrication photos breathe.]
-->

---
layout: two-cols-title
color: slate-light
align: l-lm-lm
---

:: title ::

# Drift — Fabrication

:: left ::

<img src="/images/drift/routing.jpeg" class="h-110 rounded shadow-lg" />

:: right ::

<img src="/images/drift/components.jpeg" class="h-110 rounded shadow-lg" />

<!--
The fabrication process is central to the project's interdisciplinary nature. Tim Murray fabricates resonant wood components — concentric rings designed to vibrate and amplify sound from embedded actuators. Each sculpture's form is determined by its acoustic properties: the wood species, thickness, and curvature all shape the timbre. This integration of craft, acoustics, and computation puts Drift in dialogue with sound sculptors like Zimoun's mechanical installations, Trimpin's kinetic instruments, and Olafur Eliasson's immersive sensory environments.
-->

---
layout: two-cols-title
color: slate-light
align: l-lm-lm
---

:: title ::

# Drift — Process & Outcomes

:: left ::

<img src="/images/drift/assembly.jpeg" class="w-full rounded shadow-lg" />

:: right ::

**Materials**: Microcontrollers, actuators, resonant wood, ceramic, brass, glass

**Outcomes**:
- Four installation-ready sculptures
- DSU gallery premiere + regional exhibitions
- Peer-reviewed paper (ISEA/NIME/Leonardo)
- Process documentation

**Collaborator**: Tim Murray (design & fabrication)

<!--
The finished sculptures function as what Hagood calls Orphic Media in reverse — instead of masking sound to maintain control, they surrender control, letting noise gradually organize into music through algorithmic processes. Each sculpture contains microcontrollers driving actuators that excite the resonant materials, creating evolving soundscapes visitors move through. The project integrates sound design, programming, and physical fabrication. Currently in fabrication with DSU gallery installation planned for spring 2026.
-->

---
layout: side-title
color: navy-light
align: rm-lm
titlewidth: is-4
---

:: title ::

# Future Directions

:: content ::

**Place-Based Sound Art & Ecological Documentation**

- Long-duration field recording with multi-mic approaches (stereo, hydrophone, contact mics)
- Paired digital + physical outputs: interactive map-based websites and sculptural installations with embedded speakers and sensors
- Interdisciplinary collaboration across sound, fabrication, and ecological research
- Student involvement in field recording, data collection, web development, and installation design

*Example: Above and Below — a proposed year-long soundmap of the Big Sioux River using this approach*

<!--
My research is moving toward place-based sound art that documents specific ecologies over extended time periods. The approach pairs digital and physical outputs — interactive web-based soundmaps alongside sculptural installations with embedded speakers and proximity sensors. A current example is Above and Below, a proposed year-long documentation of the Big Sioux River Greenway using stereo, hydrophone, and contact microphones to capture above-water, underwater, and vibrational perspectives. But the methodology is adaptable to any environment — rivers, coastlines, urban corridors. What I'm most excited about is the potential for student involvement at every stage: field recording campaigns, sensor data collection, web development, and physical installation design. This kind of project creates natural entry points for undergraduates across music technology, computer science, and art. [PACING: ~4 min here — end on the vision. You should be at ~45 min, leaving ~15 min for Q&A.]
-->

---
layout: default
---

# Bibliography

<div class="text-xs leading-relaxed">

- Carson, Tate. "A More Perfect Union: Composition with Audience-Controlled Smartphone Speaker Array and Evolutionary Computer Music." *Proceedings of the Web Audio Conference*. Berlin, Germany, 2018.
- Carson, Tate. "Immaterial.Cloud: Using Peer-to-Peer Technologies for Music." *Proceedings of the Web Audio Conference*. Barcelona, Spain, 2021.
- Carson, Tate. "Mesh Garden: A Creative-Based Musical Game for Participatory Musical Performance." *NIME*, 339-42. Porto Alegre, Brazil, 2019.
- Carson, Tate. "Musical Sonification of Hurricane Katrina and Its Aftermath." Master, Mills College, 2017.
- Carson, Tate. "On Ecocomposition: An Interview with Damian Keller." *Journal of Digital Media & Interaction* 3, no. 5 (2020): 133-42.
- Carson, Tate. "Philosophical Underpinnings of Environmental Music." *ICMC*. Daegu, Korea, 2018.
- Carson, Tate. "Sounds Aware: A Mobile App for Raising Awareness of Environmental Sound." *Proceedings of the Web Audio Conference*. Trondheim, Norway, 2019.
- Carson, Tate. "Systems Thinking and Environmental Interaction in the Work of Tomas Saraceno and David Dunn." *ICMC*. New York, 2019.
- Carson, Tate. "Teaching Video Game Sound: Balancing Technical Know-How with Sonic Creativity." *2023 ATMI/CMS National Conference*, Miami, Florida, 2023.
- Carson, Tate. "Using Distributed Technology to Make Music in the Time of the Attention Economy." PhD, Louisiana State University, 2021.
- Carson, Tate, and Carter Gordon. "Resonant Landscapes." *Audio Mostly 2024*, 525-32. Milan, Italy: ACM, 2024.
- Marasco, Anthony T, Tate Carson, and Matthew A Bardin. "Designing Collaborative and Mediated Experiences with Networked Circuit-Bent Devices." *SIIDS*, 2020.

</div>

---
layout: end
color: navy
---

# Questions?

tatecarson.com | tate.carson@pm.me
